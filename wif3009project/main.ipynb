{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9458d00-8e91-4d08-88ae-f2f5173b8c47",
   "metadata": {},
   "source": [
    "# A Comprehensive Analysis Of Predicting Housing Prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd574f-6b90-4e71-8a00-7e2d7ac8ca40",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the ever-evolving real estate market, accurately predicting housing prices is crucial for investors, homeowners, and policy makers alike. This project aims to leverage the power of data science to forecast housing prices based on a variety of features, including location, square footage, and additional house characteristics. Through meticulous data importing, cleaning, and manipulation, followed by exploratory data analysis (EDA), hypothesis testing, and predictive modeling, we seek to uncover the underlying patterns that drive housing prices.\n",
    "\n",
    "Our journey begins with gathering comprehensive housing data from various sources, followed by rigorous preprocessing to ensure data quality and usability. We then dive deep into the data, employing statistical and visual analysis techniques to explore relationships and trends. Hypothesis testing allows us to challenge assumptions and gain insights, while machine learning models enable us to predict prices with accuracy. Finally, we encapsulate our findings, model performance, and insights in a detailed report, complemented by visualizations to aid in understanding.\n",
    "\n",
    "This notebook serves as a structured guide through each phase of the project, from data importation to predictive analytics and reporting. Whether you're a seasoned data scientist or a curious enthusiast, this analysis aims to provide valuable insights into the dynamics of housing prices and demonstrate the power of data-driven decision-making in the real estate domain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91464597-5e04-4591-bd51-0f943a3a4148",
   "metadata": {},
   "source": [
    "# Lets Begin!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a269845",
   "metadata": {},
   "source": [
    "## Data Importing\n",
    "\n",
    "#### Here we get the dataset taken from [HERE](https://www.kaggle.com/datasets/dragonduck/property-listings-in-kuala-lumpur?resource=download)\n",
    "\n",
    "In this cell, we are importing data into our Python environment. The process of data importing involves loading data from an external source into our program. Here's what's happening in this cell:\n",
    "\n",
    "1. Importing Required Libraries:\n",
    "\n",
    "   - We are importing the pandas library, which is a powerful data manipulation library in Python. It's commonly used for data cleaning, exploration, and analysis.\n",
    "\n",
    "2. Data Loading:\n",
    "   - We are using the `pd.read_csv()` function to read a CSV file. The CSV file is a common data format that stores tabular data.\n",
    "   - The path to the CSV file is provided as an argument to the `pd.read_csv()` function. This path could be a local file path or a URL to a raw CSV file online.\n",
    "   - The data from the CSV file is loaded into a DataFrame, which is a two-dimensional tabular data structure in pandas. The DataFrame is stored in the variable `df`.\n",
    "\n",
    "After the data is loaded, we typically perform exploratory data analysis and data cleaning tasks to prepare the data for further analysis or modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed870e0-bb95-43e4-a711-0c91d1de418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d970bf5-d15b-4aad-889f-13054585de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Read the housing.csv file\n",
    "\n",
    "df = pd.read_csv(\"housing.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a8250",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "In this cell, we perform data manipulation tasks on the DataFrame `df`. The purpose of data cleaning is to clean and transform the data to make it suitable for analysis.\n",
    "\n",
    "1. Removing 'RM ' prefix and converting the 'Price' column to numeric format:\n",
    "\n",
    "   - The 'Price' column contains values formatted like \"RM 1,250,000\".\n",
    "   - We remove the 'RM ' prefix using the `str.replace()` method and replace any commas in the numbers.\n",
    "   - Then, we convert the 'Price' column to a numeric format using the `pd.to_numeric()` function.\n",
    "\n",
    "2. Filling missing values in the 'Furnishing' column with the placeholder \"Unknown\":\n",
    "\n",
    "   - We use the `fillna()` method to replace missing values in the 'Furnishing' column with the string \"Unknown\".\n",
    "\n",
    "3. Deleting rows where the 'Price' or 'Rooms' columns have missing values:\n",
    "\n",
    "   - We use the `dropna()` method to remove rows where the 'Price' or 'Rooms' columns have missing values.\n",
    "\n",
    "4. Replacing NaN values in the 'Car Parks' column with 0:\n",
    "   - We use the `fillna()` method to replace NaN values in the 'Car Parks' column with 0.\n",
    "\n",
    "After performing these data manipulation tasks, the cleaned DataFrame is displayed to verify the changes made.\n",
    "\n",
    "Summary of the DataFrame after data cleaning:\n",
    "\n",
    "- The DataFrame has a total of 51,980 entries.\n",
    "- The columns in the DataFrame are 'Location', 'Price', 'Rooms', 'Bathrooms', 'Car Parks', 'Property Type', 'Size', and 'Furnishing'.\n",
    "- The 'Price', 'Rooms', 'Bathrooms', 'Car Parks', and 'Size' columns have numeric data types.\n",
    "- The 'Location', 'Property Type', and 'Furnishing' columns have object data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f5ecc-02e7-4b01-85fb-73d237edc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'RM' prefix and convert to numeric\n",
    "df['Price'] = df['Price'].str.replace('RM ', '').str.replace(\",\", \"\")\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "\n",
    "# Fill missing values in 'Furnishing' column with 'Unknown'\n",
    "df['Furnishing'] = df['Furnishing'].fillna('Unknown')\n",
    "\n",
    "# Drop rows where 'Price' or 'Rooms' have missing values\n",
    "df = df.dropna(subset=['Price', 'Rooms'])\n",
    "\n",
    "# Replace NaN values in 'Car Parks' column with 0\n",
    "df['Car Parks'] = df['Car Parks'].fillna(0)\n",
    "\n",
    "# Define a threshold to identify rent prices\n",
    "rent_price_threshold = 10000\n",
    "\n",
    "# Filter out rent prices\n",
    "df = df[df['Price'] >= rent_price_threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ce385",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25377569-6b47-4fa7-994a-b239da324ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "# For categorical columns,want to fill NaN with a placeholder \"Unknown\"\n",
    "df['Furnishing'] = df['Furnishing'].fillna('Unknown')\n",
    "\n",
    "#Delete Row where \"Price\" is NaN\n",
    "df.dropna(subset=['Price'], inplace=True)\n",
    "\n",
    "# Delete Row where \"Rooms\" is NaN\n",
    "df.dropna(subset=['Rooms'], inplace=True)\n",
    "\n",
    "# Delete Row where \"Bathrooms\" is NaN\n",
    "df.dropna(subset=['Bathrooms'], inplace=True)\n",
    "\n",
    "# Replace NaN values in 'Car Parks' column with 0\n",
    "df['Car Parks'] = df['Car Parks'].fillna(0)\n",
    "\n",
    "# Display the cleaned DataFrame to verify changes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Converting Data Types\n",
    "\n",
    "#cleaning 'Size' column by following the regex pattern (Built-up|Land area) : (\\d{1,3},?\\d{3}|\\d{3}) sq\\. ft\\. no match mean delete the row\n",
    "df = df[df['Size'].str.match(r'(Built-up|Land area) : (\\d{1,3},?\\d{3}|\\d{3}) sq\\. ft\\.', na=False)]\n",
    "\n",
    "# Extracting Numeric Data from 'Size' column\n",
    "df['Size'] = df['Size'].str.extract(r'(\\d+,\\d+|\\d+)').replace(',', '', regex=True).astype(float)\n",
    "\n",
    "#rename the column 'Size' to 'Sqft'\n",
    "df.rename(columns={'Size': 'Sqft'}, inplace=True)\n",
    "\n",
    "#remove the () in 'Property Type' column and remove spaces in the beginning and end of the string\n",
    "df['Property Type'] = df['Property Type'].str.replace(r\"\\(.*\\)\", \"\", regex=True)\n",
    "df['Property Type'] = df['Property Type'].str.strip()\n",
    "\n",
    "\n",
    "#'Rooms' should be numeric, we need a custom function to handle \"2+1\" cases\n",
    "def convert_rooms(room):\n",
    "\n",
    "    if pd.isnull(room):\n",
    "        return np.nan  # Return NaN for missing values\n",
    "    \n",
    "    parts = room.split('+')\n",
    "\n",
    "    if len(parts) == 2:\n",
    "\n",
    "        if parts[1] != \"\": # Check if the second part is not empty (e.g. \"2+\")\n",
    "\n",
    "            return float(parts[0]) + float(parts[1])  # Example conversion: \"2+1\" becomes 3.0\n",
    "        \n",
    "        else:\n",
    "\n",
    "            return float(parts[0])\n",
    "    try:\n",
    "\n",
    "        return float(room)\n",
    "    \n",
    "    except ValueError:\n",
    "        return np.nan  # Return NaN if conversion fails\n",
    "\n",
    "# Apply the custom function to 'Rooms' column\n",
    "df['Rooms'] = df['Rooms'].apply(convert_rooms)\n",
    "df.dropna(subset=['Rooms'], inplace=True)\n",
    "\n",
    "# Handling Infinite Values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame to verify changes\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483be03-4634-4e41-bcc1-9a3d30e0fcd7",
   "metadata": {},
   "source": [
    "## Data Manipulation ‚úèÔ∏è\n",
    "\n",
    "In this cell, we are performing several data manipulation tasks on the DataFrame `df`. Here's what's happening:\n",
    "\n",
    "Installing the `scikit-learn` used for ML eventually and Labeling\n",
    "\n",
    "1. One-Hot Encoding:\n",
    "\n",
    "   - The 'Furnishing' column is being encoded using one-hot encoding. This is a process of converting categorical data variables so they can be provided to machine learning algorithms to improve predictions. With one-hot, we convert each category value into a new column and assign a 1 or 0 (True/False) value to the column Also Droping the `Furnishing_Unknown` column from the table s.\n",
    "\n",
    "2. Outlier Removal:\n",
    "\n",
    "   - The function `IQR_outliers()` is defined to remove outliers from a specified column of the DataFrame. Outliers are extreme values that deviate from other observations on data, they may indicate a variability in a measurement, experimental errors or a novelty. In other words, an outlier is an observation that diverges from an overall pattern on a sample.\n",
    "   - The function calculates the Interquartile Range (IQR), which is a measure of statistical dispersion, and uses it to define the upper and lower bounds for outliers. Any data points that fall below the lower bound or above the upper bound are considered outliers.\n",
    "   - This function is applied to the 'Price' and 'Size' columns of the DataFrame.\n",
    "\n",
    "3. Feature Engineering:\n",
    "\n",
    "   - A new column 'Price per Sqft' is created by dividing the 'Price' column by the 'Size' column. This could provide a more standardized measure of price that takes into account the size of the property.\n",
    "\n",
    "4. Label Encoding:\n",
    "   - The 'Property Type' column is being encoded using label encoding. This is a popular encoding technique for handling categorical variables. In this technique, each label is assigned a unique integer based on alphabetical ordering.\n",
    "\n",
    "Finally, the first few rows of the cleaned DataFrame are displayed to verify the changes.\n",
    "\n",
    "### Label Encoding of 'Property Type'\n",
    "\n",
    "0 -> 1-sty Terrace/Link House\n",
    "\n",
    "1 -> 1.5-sty Terrace/Link House\n",
    "\n",
    "2 -> 2-sty Terrace/Link House\n",
    "\n",
    "3 -> 2.5-sty Terrace/Link House\n",
    "\n",
    "4 -> 3-sty Terrace/Link House\n",
    "\n",
    "5 -> 3.5-sty Terrace/Link House\n",
    "\n",
    "6 -> 4-sty Terrace/Link House\n",
    "\n",
    "7 -> 4.5-sty Terrace/Link House\n",
    "\n",
    "8 -> Apartment\n",
    "\n",
    "9 -> Bungalow\n",
    "\n",
    "10 -> Cluster House\n",
    "\n",
    "11 -> Condominium\n",
    "\n",
    "12 -> Flat\n",
    "\n",
    "13 -> Residential Land\n",
    "\n",
    "14 -> Semi-detached House\n",
    "\n",
    "15 -> Serviced Residence\n",
    "\n",
    "16 -> Townhouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6834b8-f49b-4140-a288-bb7c2749aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'Furnishing' column using one-hot encoding\n",
    "if 'Furnishing' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['Furnishing'], prefix='Furnishing')\n",
    "    # Remove row with \"Furnishing_Unknown\" column\n",
    "    df = df.drop(columns=['Furnishing_Unknown'])\n",
    "else:\n",
    "    print(\"The 'Furnishing' column is not present in the DataFrame.\")\n",
    "\n",
    "\n",
    "# Remove extreme outliers in 'Sqft' column\n",
    "df = df[df['Sqft'] <= 10000]  # Adjust the threshold as needed\n",
    "\n",
    "df['PricePerSqft'] = df['Price'] / df['Sqft']\n",
    "\n",
    "# Remove outliers using Interquartile Range (IQR)\n",
    "def IQR_outliers(df, column, multiplier):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    return df[(df[column] > lower_bound) & (df[column] < upper_bound)]\n",
    "\n",
    "df = IQR_outliers(df, 'PricePerSqft', multiplier=1.0)  # Stricter threshold\n",
    "df = IQR_outliers(df, 'Price', multiplier=1.0)  # Stricter threshold\n",
    "df = IQR_outliers(df, 'Sqft', multiplier=1.0)  # Stricter threshold\n",
    "\n",
    "# Remove outliers using Median Absolute Deviation (MAD)\n",
    "def MAD_outliers(df, column, threshold):\n",
    "    median = df[column].median()\n",
    "    deviations = abs(df[column] - median)\n",
    "    MAD = deviations.median()\n",
    "    lower_bound = median - threshold * MAD\n",
    "    upper_bound = median + threshold * MAD\n",
    "    return df[(df[column] > lower_bound) & (df[column] < upper_bound)]\n",
    "\n",
    "df = MAD_outliers(df, 'Price', threshold=2.5)  # Stricter threshold\n",
    "df = MAD_outliers(df, 'Sqft', threshold=2.5)  # Stricter threshold\n",
    "\n",
    "# Remove outliers using z-score\n",
    "from scipy import stats\n",
    "df = df[(np.abs(stats.zscore(df['Price'])) < 2.5)]  # Stricter threshold\n",
    "df = df[(np.abs(stats.zscore(df['Sqft'])) < 2.5)]  # Stricter threshold\n",
    "df = df[(np.abs(stats.zscore(df['Rooms'])) < 2.5)]  # Stricter threshold\n",
    "df = df[(np.abs(stats.zscore(df['Bathrooms'])) < 2.5)]  # Stricter threshold\n",
    "df = df[(np.abs(stats.zscore(df['Car Parks'])) < 2.5)]  # Stricter threshold\n",
    "df = df[(np.abs(stats.zscore(df['PricePerSqft'])) < 2.5)]  # Stricter threshold\n",
    "\n",
    "# Label encode the 'Property Type' column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['Property Type'] = label_encoder.fit_transform(df['Property Type'])\n",
    "\n",
    "# Encode the 'Location' column\n",
    "df[\"Location\"] = df[\"Location\"].str.replace(\", Kuala Lumpur\", \"\")\n",
    "df['Location'] = label_encoder.fit_transform(df['Location'])\n",
    "\n",
    "# Display the cleaned DataFrame to verify changes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc4b5ff-bb74-490f-b219-18ad32578b81",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) and Visualization üìä üìà\n",
    "\n",
    "Exploratory Data Analysis (EDA) allows us to dive deep into the dataset, uncovering patterns, relationships, and insights. Through visualizations such as histograms, scatter plots, and heatmaps, we gain a comprehensive understanding of the data's characteristics and the factors influencing housing prices. This visual and statistical exploration is pivotal in guiding our hypothesis testing and predictive modeling efforts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "\n",
    "%pip install seaborn\n",
    "\n",
    "%pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b20fbf-e58f-4121-a252-65ecdc74c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the summary statistics of the cleaned DataFrame\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f7b8d",
   "metadata": {},
   "source": [
    "### Distribution Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Create subplots for histograms\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "# Plot histograms for 'Price', 'Rooms', 'Bathrooms', 'Car Parks', 'Sqft', and 'Price per Sqft'\n",
    "\n",
    "# Custom formatter function to display numbers in thousands (K) and millions (M)\n",
    "def custom_formatter(x, pos):\n",
    "    if x >= 1e6:  # If 1 million or more\n",
    "        return '{:,.1f}M'.format(x*1e-6)  # Convert to M\n",
    "    elif x >= 1e3:  # If 1 thousand or more\n",
    "        return '{:,.0f}K'.format(x*1e-3)  # Convert to K\n",
    "    else:\n",
    "        return '{:,.0f}'.format(x)  # No suffix\n",
    "\n",
    "axs[0, 0].hist(df['Price'], bins=20, color='skyblue')\n",
    "axs[0, 0].set_title('Price')\n",
    "axs[0,0].xaxis.set_major_formatter(ticker.FuncFormatter(custom_formatter))\n",
    "\n",
    "axs[0, 1].hist(df['Rooms'], bins=20, color='lightgreen')\n",
    "axs[0, 1].set_title('Rooms')\n",
    "\n",
    "axs[0, 2].hist(df['Bathrooms'], bins=20, color='lightcoral')\n",
    "axs[0, 2].set_title('Bathrooms')\n",
    "\n",
    "axs[1, 0].hist(df['Car Parks'], bins=20, color='gold')\n",
    "axs[1, 0].set_title('Car Parks')\n",
    "\n",
    "axs[1, 1].hist(df['Sqft'], bins=20, color='lightblue')\n",
    "axs[1, 1].set_title('Sqft')\n",
    "\n",
    "axs[1, 2].hist(df['PricePerSqft'], bins=20, color='pink')\n",
    "axs[1, 2].set_title('Price per Sqft')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# use plotly to create a scatter plot of 'Price' vs 'Sqft'\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a scatter plot of 'Price' vs 'Sqft'\n",
    "\n",
    "fig = px.scatter(df, x='Sqft', y='Price', title='Price vs. Sqft', labels={'Sqft': 'Sqft (sq. ft.)', 'Price': 'Price (RM)'})\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf1c16",
   "metadata": {},
   "source": [
    "# TODO: EXPLAINING THE ABOVE ‚¨ÜÔ∏è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f28414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create subplots for box plots\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "\n",
    "# Plot box plots for 'Price', 'Rooms', 'Bathrooms', 'Car Parks', and 'Sqft'\n",
    "axs[0].boxplot(df['Price'])\n",
    "axs[0].set_title('Price')\n",
    "axs[0].yaxis.set_major_formatter(ticker.FuncFormatter(custom_formatter))\n",
    "\n",
    "axs[1].boxplot(df['Rooms'])\n",
    "axs[1].set_title('Rooms')\n",
    "axs[2].boxplot(df['Bathrooms'])\n",
    "axs[2].set_title('Bathrooms')\n",
    "axs[3].boxplot(df['Car Parks'])\n",
    "axs[3].set_title('Car Parks')\n",
    "axs[4].boxplot(df['Sqft'])\n",
    "axs[4].set_title('Sqft')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec606856-58ec-4f52-92a5-803a2f7948c7",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Armed with insights from our EDA, we formulate and test hypotheses regarding factors that may influence housing prices. Utilizing statistical tests, such as t-tests or chi-square tests, we assess the validity of these hypotheses, providing a data-driven foundation for our predictive models. This step is crucial for identifying significant variables and relationships within our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70859ad0-5b78-4457-9ceb-46348fc8a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a334e2-a21e-4a4f-9e6a-be7b7841d73f",
   "metadata": {},
   "source": [
    "## Predictive Analytics (Machine Learning / Deep Learning)\n",
    "\n",
    "Transitioning from analysis to prediction, we employ machine learning models to forecast housing prices. This phase involves splitting our data into training and testing sets, selecting appropriate models, and training them on our dataset. Through model evaluation, we assess the accuracy and effectiveness of our predictions, striving for models that offer both high precision and generalizability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b52b5-a782-48b7-a55b-9c663f2db24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df.drop(columns=['Price'])\n",
    "y = df['Price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# graph the model history\n",
    "\n",
    "# Predict the target on the training data\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Predict the target on the testing data\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error on the training and testing data\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f'Train MSE: {train_mse:.2f}')\n",
    "\n",
    "print(f'Test MSE: {test_mse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b67b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Train R-squared: {train_r2:.2f}')\n",
    "print(f'Test R-squared: {test_r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2bdc5-22d3-4f2a-9d40-7d52060e8d2f",
   "metadata": {},
   "source": [
    "## Extra Bonus Components\n",
    "\n",
    "Beyond the core components of our project, we explore additional enhancements such as web deployment, dashboard creation, prescriptive analytics, and GUI development. These extra features aim to extend the applicability and accessibility of our analysis, offering real-time insights, interactive visualizations, and user-friendly interfaces for diverse audiences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528b794-879c-49ef-b220-3ed44014ca80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
